# Magic Prompt

**RU • Локальный многоуровневый помощник, который превращает идею в готовый промпт для генерации изображений.**  
**EN • Local multi-layer assistant that turns a rough idea into a production-ready image prompt.**

---

## RU — О проекте
- Готовит промпты для моделей ChatGPT, Midjourney и других генераторов изображений.
- Работает полностью офлайн через связку `ollama` + локальные модели (стартуем с `mistral`).
- Предлагает многоуровневый процесс: от идеи пользователя → уточнение контекста → стилизация → финальный промпт.
- Обеспечивает приватность (нет внешних API) и повторяемость результата.

## EN — Project Overview
- Crafts prompts for ChatGPT, Midjourney, and other image models.
- Runs fully offline via `ollama` with local models (initially `mistral`).
- Guides the user through layered refinement: raw idea → context expansion → style tuning → final prompt package.
- Keeps conversations private and deterministic.

---

## Ключевые возможности / Key Capabilities
- **Многоуровневое уточнение**: пошаговые слои (идея → сюжет → стиль → техника → финальный текст).
- **Шаблоны сцен**: готовые пресеты для категорий (бренд, персонаж, окружение, UI) с адаптацией под модель.
- **Совместная доска**: единый рабочий экран, где видно прогресс, варианты, заметки и историю.
- **Билингвальная выдача**: каждый финальный промпт доступен на русском и английском.
- **Локальное хранение**: сохранение библиотек промптов, тегов и версий в локальной базе.
- **Пакетное улучшение**: загрузка списка идей и генерация серии промптов по единому стилю.

---

## Архитектура / Architecture
- **Core Engine**: Python-приложение, управляющее этапами диалога, правилами стилизации и агрегирующее ответы LLM.
- **Model Layer**: Ollama + локальные модели (`mistral` для начала, планируем `llama3`, `phi-3`).
- **Prompt Graph**: формализованное описание этапов (узлы — вопросы, рёбра — варианты переходов). Позволяет расширять сценарии без переписывания кода.
- **Storage**: локальная БД (легковесная SQLite) + файловое хранилище для экспорта промптов.
- **UI Layer**: десктопное приложение на `PySide6` (Qt) с тематической розово-снежной палитрой, поддержкой drag & drop и предпросмотром состояний.
- **Localization**: система строк с fallback, перевод интерфейса и содержимого промптов RU ⇄ EN.

---

## UX & UI
- **Стиль**: воздушная розово-снежная палитра (`#FFE4F3`, `#F7F9FB`, глубокие акценты `#FF76B8`), мягкие тени и стеклянные панели.
- **Интерфейс**: панель этапов слева, рабочее пространство по центру, инспектор настроек справа; sticky-хедер с переключателем RU/EN и индикатором прогресса.
- **Виджеты**: карточки уровней, редактор подсказок, предпросмотр финального промпта, журнал изменений, модальные окна для пресетов.
- **Анимации**: лёгкий blur и снежные частицы в фоне при загрузке, микровзаимодействия при выборе слоя.
- **Фреймворк**: `PySide6` с кастомными стилями через Qt Style Sheets, без использования Tkinter.

---

## UI Stack & Prototype
- **Каркас**: `PySide6` + `QtQuick` для динамических элементов. Основой служит `MainWindow`, разделённый на три панели `QSplitter`.
- **Компоненты**:
  - `StageSidebar` — список слоёв из Prompt Graph с визуализацией прогресса (badge, снежный индикатор).
  - `CanvasView` — центральная сцена с карточками вопросов, превью RU/EN и переключателем «Simple / Advanced».
  - `InsightPanel` — правая колонка с шаблонами, историей версий и быстрыми тегами.
  - `PromptPreviewDialog` — модальное окно с финальным пакетом промптов и кнопками экспорта.
- **Темы**: общая система токенов (`color.primary`, `color.backgroundSnow`, `radius.soft`, `shadow.light`). Токены хранятся в `theme.json` и конвертируются в Qt Style Sheet.
- **Прототип**: сначала статичная сцена с мок-данными Prompt Graph, затем связываем с реальным `PromptGraph` из `prompt_graph.py`.
- **Простота**: минимальное количество кликов — каждая карточка раскрывается инлайн, без доп. окон; быстрые пресеты в верхней панели.

---

## Локализация / Localization
- Все тексты интерфейса и подсказки хранятся в структуре `locales/{ru,en}.json`.
- Переключение языка на лету, синхронное отображение RU/EN в финальных промптах.
- Планируется автоперевод пользовательского ввода (offline-модель или LLM), fallback — встроенный двунаправленный перевод.

---

## Дорожная карта / Roadmap
1. **CLI MVP**
   - Многошаговый сценарий внутри терминала.
   - Экспорт RU/EN промптов в Markdown/JSON.
2. **UI v1**
   - Статичный розовый интерфейс с пресетами.
   - Редактирование и повторная генерация отдельных слоёв.
3. **Prompt Library**
   - Каталог шаблонов, поиск, теги и версии.
   - Импорт/экспорт коллекций промптов.
4. **Collaboration & Automation**
   - Пакетная обработка идей, общие библиотеки и API-интеграция.

---

## Требования / Requirements
-

---

## Установка / Setup

```bash
# 1. Установить Ollama и требуемые модели
ollama run mistral

# 2. Установить зависимости Python
pip install ollama

# 3. Запуск текущей CLI-версии
python chat.py
```

### UI Preview (PySide6)

```bash
# Доп. зависимость
pip install PySide6

# Headless smoke-test (полезно в CI/WSL)
python app.py --smoke --headless --lang ru

# Полноценный запуск
python app.py --lang ru
```
en
---

## Следующие шаги / Next Steps
- Подключить `PromptGraph` к текущему CLI, добавить экспорт RU/EN и сохранение состояния.
- Расширить PySide6-интерфейс данными от LLM (динамические ответы, история).
- Настроить загрузчик локализаций из `locales/` и привязать строки к UI-слоям.
- Спроектировать хранилище проектов (SQLite) и API для библиотек шаблонов.
